{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use surprise to build recsys engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = '../dataset/dataset1'\n",
    "movie_file_name = 'movie.csv'\n",
    "user_file_name = 'user.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv(os.path.join(src_folder, movie_file_name))\n",
    "user_df = pd.read_csv(os.path.join(src_folder, user_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple eda on user rating and movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- is movie contains nan ----------\n",
      "类型     False\n",
      "主演     False\n",
      "地区     False\n",
      "导演     False\n",
      "特色     False\n",
      "评分     False\n",
      "电影名    False\n",
      "dtype: bool\n",
      "---------- is user contains nan ----------\n",
      "评分      False\n",
      "用户名     False\n",
      "评论时间    False\n",
      "用户ID    False\n",
      "电影名     False\n",
      "类型      False\n",
      "dtype: bool\n",
      "---------- movie data set info ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93160 entries, 0 to 93159\n",
      "Data columns (total 7 columns):\n",
      "类型     93160 non-null object\n",
      "主演     93160 non-null object\n",
      "地区     93160 non-null object\n",
      "导演     93160 non-null object\n",
      "特色     93160 non-null object\n",
      "评分     93160 non-null float64\n",
      "电影名    93160 non-null object\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 5.0+ MB\n",
      "None\n",
      "---------- user data set info ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199813 entries, 0 to 199812\n",
      "Data columns (total 6 columns):\n",
      "评分      199813 non-null int64\n",
      "用户名     199813 non-null object\n",
      "评论时间    199813 non-null object\n",
      "用户ID    199813 non-null int64\n",
      "电影名     199813 non-null object\n",
      "类型      199813 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 9.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# analyse data\n",
    "print(('-'*10 + ' {} ' + '-'*10).format(\"is movie contains nan\"))\n",
    "print(movie_df.isna().any())\n",
    "print(('-'*10 + ' {} ' + '-'*10).format(\"is user contains nan\"))\n",
    "print(user_df.isna().any())\n",
    "print(('-'*10 + ' {} ' + '-'*10).format(\"movie data set info\"))\n",
    "print(movie_df.info())\n",
    "print(('-'*10 + ' {} ' + '-'*10).format(\"user data set info\"))\n",
    "print(user_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie in user_df length is 23031 and movie in movie_df length is 23034\n",
      "difference\n",
      "{'粉骚大联盟', '新雪国', '当狗狗在停车场'}\n",
      "number of users is 13545\n",
      "number of movies is 23031\n"
     ]
    }
   ],
   "source": [
    "user_df_movie_set = set(np.unique(user_df['电影名']))\n",
    "movie_df_movie_set = set(np.unique(movie_df['电影名']))\n",
    "print(\"movie in user_df length is {} and movie in movie_df length is {}\".format(len(user_df_movie_set), len(movie_df_movie_set)))\n",
    "print(\"difference\")\n",
    "print(movie_df_movie_set - user_df_movie_set)\n",
    "print(\"number of users is {}\".format(len(np.unique(user_df['用户ID']))))\n",
    "print(\"number of movies is {}\".format(len(np.unique(user_df['电影名']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate surprise data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_df = user_df[['用户ID', '电影名', '评分']]\n",
    "user_m = user_df[['用户ID', '用户名']].drop_duplicates\n",
    "rating_scale = (np.unique(surprise_df['评分']).min(), np.unique(surprise_df['评分']).max())\n",
    "reader = Reader(rating_scale = rating_scale)\n",
    "surprise_data =  Dataset.load_from_df(surprise_df, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------start training----------\n",
      "----------duration 116.931 s----------\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "import time\n",
    "alg = SVD(random_state=0)\n",
    "# fit on the whole data set\n",
    "# define the parameters\n",
    "\n",
    "param_grid = {\n",
    "              'lr_all': [0.001, 0.005],\n",
    "              'reg_all': [0.01, 0.1]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "print(('-'*10 + \"{}\" + '-'*10).format(\"start training\"))\n",
    "start = time.time()\n",
    "gs.fit(surprise_data)\n",
    "duration = round(time.time() - start, 3)\n",
    "print(('-'*10 + \"{}\" + '-'*10).format(\"duration \" + str(duration) + \" s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rmse params\n",
      "{'lr_all': 0.005, 'reg_all': 0.01}\n",
      "best maae params\n",
      "{'lr_all': 0.005, 'reg_all': 0.01}\n",
      "best score rmse\n",
      "2.3292249281154214\n",
      "best score mae\n",
      "1.9202335468921257\n"
     ]
    }
   ],
   "source": [
    "#best params\n",
    "print('best rmse params')\n",
    "print(gs.best_params['rmse'])\n",
    "print('best maae params')\n",
    "print(gs.best_params['mae'])\n",
    "print('best score rmse')\n",
    "print(gs.best_score['rmse'])\n",
    "print('best score mae')\n",
    "print(gs.best_score['mae'])\n",
    "algo = gs.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fa5bbb4c828>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain the model with all the data\n",
    "all_train_set=surprise_data.build_full_trainset()\n",
    "algo.fit(all_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict and recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_USER_COL = \"用户ID\"\n",
    "DEFAULT_ITEM_COL = \"电影名\"\n",
    "DEFAULT_RATING_COL = \"评分\"\n",
    "DEFAULT_LABEL_COL = \"label\"\n",
    "DEFAULT_TIMESTAMP_COL = \"timestamp\"\n",
    "DEFAULT_PREDICTION_COL = \"预估评分\"\n",
    "COL_DICT = {\n",
    "    \"col_user\": DEFAULT_USER_COL,\n",
    "    \"col_item\": DEFAULT_ITEM_COL,\n",
    "    \"col_rating\": DEFAULT_RATING_COL,\n",
    "    \"col_prediction\": DEFAULT_PREDICTION_COL,\n",
    "}\n",
    "\n",
    "# Filtering variables\n",
    "DEFAULT_K = 10\n",
    "DEFAULT_THRESHOLD = 10\n",
    "\n",
    "# Other\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def predict(algo,\n",
    "    data,\n",
    "    usercol=DEFAULT_USER_COL,\n",
    "    itemcol=DEFAULT_ITEM_COL,\n",
    "    predcol=DEFAULT_PREDICTION_COL\n",
    "):\n",
    "    '''\n",
    "    given the dataframe and predict the r_ui\n",
    "    '''\n",
    "    # get the predictions of current data frame\n",
    "    # prediction: uid iid r_ui estimated rating\n",
    "    predictions = [\n",
    "        algo.predict(getattr(row, usercol), getattr(row, itemcol))\n",
    "        for row in data.itertuples()\n",
    "    ]\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    predictions = predictions.rename(\n",
    "        index=str, columns={\"uid\": usercol, \"iid\": itemcol, \"est\": predcol}\n",
    "    )\n",
    "    return predictions.drop([\"details\", \"r_ui\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking(algo,\n",
    "    data,\n",
    "    usercol=DEFAULT_USER_COL,\n",
    "    itemcol=DEFAULT_ITEM_COL,\n",
    "    predcol=DEFAULT_PREDICTION_COL,\n",
    "    remove_seen=False\n",
    "):\n",
    "    '''\n",
    "    calculate the score and rank\n",
    "    '''\n",
    "    preds_lst = []\n",
    "    users = data[usercol].unique()\n",
    "    items = data[itemcol].unique()\n",
    "\n",
    "    for user in users:\n",
    "        for item in items:\n",
    "            preds_lst.append([user, item, algo.predict(user, item).est])\n",
    "\n",
    "    all_predictions = pd.DataFrame(data=preds_lst, columns=[usercol, itemcol, predcol])\n",
    "\n",
    "    if remove_seen:\n",
    "        tempdf = pd.concat(\n",
    "            [\n",
    "                data[[usercol, itemcol]],\n",
    "                pd.DataFrame(\n",
    "                    data=np.ones(data.shape[0]), columns=[\"dummycol\"], index=data.index\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        merged = pd.merge(tempdf, all_predictions, on=[usercol, itemcol], how=\"outer\")\n",
    "        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    用户ID   电影名      预估评分\n",
      "0  11279  前路漫漫  6.137563\n",
      "1  19564   麦尔斯  7.982444\n",
      "2  13273  青春罩杯  9.088771\n",
      "3   4549  甘泉玛侬  8.689167\n",
      "4  12644  一个勺子  4.862729\n",
      "    用户ID   电影名      预估评分\n",
      "0  11279  前路漫漫  6.137563\n",
      "1  11279   麦尔斯  7.998595\n",
      "2  11279  青春罩杯  7.989352\n",
      "3  11279  甘泉玛侬  7.712024\n",
      "4  11279  一个勺子  6.523887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(surprise_df, test_size=0.25, random_state=0)\n",
    "test_predictions = predict(algo, test_set)\n",
    "print(test_predictions.head())\n",
    "test_ranking = compute_ranking(algo, test_set)\n",
    "print(test_ranking.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate the SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_items(\n",
    "    dataframe, col_user=DEFAULT_USER_COL, col_rating=DEFAULT_RATING_COL, k=DEFAULT_K\n",
    "):\n",
    "    if k is None:\n",
    "        top_k_items = dataframe\n",
    "    else:\n",
    "        top_k_items = (\n",
    "            dataframe.groupby(col_user, as_index=False)\n",
    "            .apply(lambda x: x.nlargest(k, col_rating))\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    top_k_items[\"rank\"] = top_k_items.groupby(col_user, sort=False).cumcount() + 1\n",
    "    return top_k_items\n",
    "\n",
    "def merge_ranking_true_pred(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user,\n",
    "    col_item,\n",
    "    col_rating,\n",
    "    col_prediction,\n",
    "    relevancy_method='top_k',\n",
    "    k=DEFAULT_K,\n",
    "    threshold=DEFAULT_THRESHOLD\n",
    "):\n",
    "    common_users = set(rating_true[col_user]).intersection(set(rating_pred[col_user]))\n",
    "    rating_true_common = rating_true[rating_true[col_user].isin(common_users)]\n",
    "    rating_pred_common = rating_pred[rating_pred[col_user].isin(common_users)]\n",
    "    n_users = len(common_users)\n",
    "    \n",
    "    if relevancy_method == \"top_k\":\n",
    "        top_k = k\n",
    "    elif relevancy_method == \"by_threshold\":\n",
    "        top_k = threshold\n",
    "    elif relevancy_method is None:\n",
    "        top_k = None\n",
    "    else:\n",
    "        raise NotImplementedError(\"Invalid relevancy_method\")\n",
    "    df_hit = get_top_k_items(\n",
    "        dataframe=rating_pred_common,\n",
    "        col_user=col_user,\n",
    "        col_rating=col_prediction,\n",
    "        k=top_k,\n",
    "    )\n",
    "    df_hit = pd.merge(df_hit, rating_true_common, on=[col_user, col_item])[\n",
    "        [col_user, col_item, \"rank\"]\n",
    "    ]\n",
    "\n",
    "    # count the number of hits vs actual relevant items per user\n",
    "    df_hit_count = pd.merge(\n",
    "        df_hit.groupby(col_user, as_index=False)[col_user].agg({\"hit\": \"count\"}),\n",
    "        rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n",
    "            {\"actual\": \"count\"}\n",
    "        ),\n",
    "        on=col_user,\n",
    "    )\n",
    "\n",
    "    return df_hit, df_hit_count, n_users\n",
    "\n",
    "def map_eval(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user=DEFAULT_USER_COL,\n",
    "    col_item=DEFAULT_ITEM_COL,\n",
    "    col_rating=DEFAULT_RATING_COL,\n",
    "    col_prediction=DEFAULT_PREDICTION_COL,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=DEFAULT_K,\n",
    "    threshold=DEFAULT_THRESHOLD,\n",
    "):\n",
    "    df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    if df_hit.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # calculate reciprocal rank of items for each user and sum them up\n",
    "    df_hit_sorted = df_hit.copy()\n",
    "    df_hit_sorted[\"rr\"] = (\n",
    "        df_hit_sorted.groupby(col_user).cumcount() + 1\n",
    "    ) / df_hit_sorted[\"rank\"]\n",
    "    df_hit_sorted = df_hit_sorted.groupby(col_user).agg({\"rr\": \"sum\"}).reset_index()\n",
    "\n",
    "    df_merge = pd.merge(df_hit_sorted, df_hit_count, on=col_user)\n",
    "    return (df_merge[\"rr\"] / df_merge[\"actual\"]).sum() / n_users\n",
    "\n",
    "def ndcg_eval(rating_true,\n",
    "    rating_pred,\n",
    "    col_user=DEFAULT_USER_COL,\n",
    "    col_item=DEFAULT_ITEM_COL,\n",
    "    col_rating=DEFAULT_RATING_COL,\n",
    "    col_prediction=DEFAULT_PREDICTION_COL,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=DEFAULT_K,\n",
    "    threshold=DEFAULT_THRESHOLD\n",
    "):\n",
    "    df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    if df_hit.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # calculate discounted gain for hit items\n",
    "    df_dcg = df_hit.copy()\n",
    "    # relevance in this case is always 1\n",
    "    df_dcg[\"dcg\"] = 1 / np.log1p(df_dcg[\"rank\"])\n",
    "    # sum up discount gained to get discount cumulative gain\n",
    "    df_dcg = df_dcg.groupby(col_user, as_index=False, sort=False).agg({\"dcg\": \"sum\"})\n",
    "    # calculate ideal discounted cumulative gain\n",
    "    df_ndcg = pd.merge(df_dcg, df_hit_count, on=[col_user])\n",
    "    df_ndcg[\"idcg\"] = df_ndcg[\"actual\"].apply(\n",
    "        lambda x: sum(1 / np.log1p(range(1, min(x, k) + 1)))\n",
    "    )\n",
    "\n",
    "    # DCG over IDCG is the normalized DCG\n",
    "    return (df_ndcg[\"dcg\"] / df_ndcg[\"idcg\"]).sum() / n_users\n",
    "\n",
    "def precision_eval(rating_true,\n",
    "    rating_pred,\n",
    "    col_user=DEFAULT_USER_COL,\n",
    "    col_item=DEFAULT_ITEM_COL,\n",
    "    col_rating=DEFAULT_RATING_COL,\n",
    "    col_prediction=DEFAULT_PREDICTION_COL,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=DEFAULT_K,\n",
    "    threshold=DEFAULT_THRESHOLD\n",
    "):\n",
    "    df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    if df_hit.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return (df_hit_count[\"hit\"] / k).sum() / n_users\n",
    "\n",
    "\n",
    "def recall_eval(rating_true,\n",
    "    rating_pred,\n",
    "    col_user=DEFAULT_USER_COL,\n",
    "    col_item=DEFAULT_ITEM_COL,\n",
    "    col_rating=DEFAULT_RATING_COL,\n",
    "    col_prediction=DEFAULT_PREDICTION_COL,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=DEFAULT_K,\n",
    "    threshold=DEFAULT_THRESHOLD\n",
    "):\n",
    "    df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    if df_hit.shape[0] == 0:\n",
    "        return 0.0\n",
    "    return (df_hit_count[\"hit\"] / df_hit_count[\"actual\"]).sum() / n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = compute_ranking(algo, train_set, remove_seen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "eval_map = map_eval(test, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_ndcg = ndcg_eval(test, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_precision = precision_eval(test, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_recall = recall_eval(test, all_predictions, col_prediction='prediction', k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"map: {}\".format(eval_map))\n",
    "print(\"ndcg: {}\".format(eval_ndcg))\n",
    "print(\"precision: {}\".format(eval_precision))\n",
    "print(\"recall: {}\".format(eval_recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "587px",
    "left": "609px",
    "top": "236px",
    "width": "249.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
