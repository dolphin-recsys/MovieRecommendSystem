{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "my_seed = 1337\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "from typing import *\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step one加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_data\n",
      " (188843, 6)\n",
      "   评分     用户名                评论时间  用户ID    电影名  类型\n",
      "0   2      身似 2018-01-05 15:05:06     1   心雨花露  爱情\n",
      "1   4  有意识的贱民 2018-01-05 15:05:06     3  战争的恐怖  战争\n",
      "2   2    亿万露电 2018-01-05 15:05:06     4  豪勇七蛟龙  战争\n",
      "3   2   Marni 2018-01-05 15:05:06     5   无序之主  犯罪\n",
      "4   4   马西嘻嘻嘻 2018-01-05 15:05:06     6  时装店风波  同性\n"
     ]
    }
   ],
   "source": [
    "def name_to_id():\n",
    "    movie_data_columns = [\n",
    "    'type', 'actor', 'region', 'director', 'characteristic',\n",
    "    'score', 'moviename']\n",
    "    movie_data = pd.read_csv(data_dir + './dataset1/movie.csv')\n",
    "    movie_data.columns = movie_data_columns\n",
    "    movie_unique = movie_data['moviename'].unique()\n",
    "    movie_name_to_uninque_index = dict()\n",
    "    movie_index_to_uninque_name = dict()\n",
    "    for  i,j in enumerate(movie_unique):\n",
    "        if i <=22971:\n",
    "            movie_name_to_uninque_index[j] = i\n",
    "            movie_index_to_uninque_name[i] = j\n",
    "        elif i > 22971:\n",
    "            print('error')\n",
    "    return movie_name_to_uninque_index,movie_index_to_uninque_name\n",
    "\n",
    "def load_movies_dataset():\n",
    "    movie_data = pd.read_csv(data_dir + './dataset1/movie.csv')\n",
    "    movie_data = movie_data.rename(columns = {'评分': \"豆瓣网评分\"})\n",
    "    return movie_data \n",
    "\n",
    "def load_user_and_ratings() :\n",
    "    user_data = pd.read_csv(data_dir + './dataset1/user.csv')\n",
    "    print('user_data\\n',user_data.shape)\n",
    "    user_data['评论时间'] = pd.to_datetime(user_data['评论时间'])   \n",
    "    return user_data \n",
    "\n",
    "\n",
    "\n",
    "data_dir = 'D:/python/Jupyter_Last_project/dataset/'\n",
    "user_rating_data = load_user_and_ratings()\n",
    "print(user_rating_data.head())\n",
    "u_data = user_rating_data[['用户ID', '电影名', '评分']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>用户ID</th>\n",
       "      <th>用户观看电影个数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   用户ID  用户观看电影个数\n",
       "0     1         5\n",
       "1     3       132\n",
       "2     4        15\n",
       "3     5        27\n",
       "4     6        87"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_temp = u_data.groupby('用户ID').电影名.size().reset_index()\n",
    "\n",
    "u_temp = u_temp.rename(columns = {'电影名': \"用户观看电影个数\"})\n",
    "u_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2625"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_temp['用户观看电影个数'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.941897379106681"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_temp['用户观看电影个数'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_temp['用户观看电影个数'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一些必要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split as sk_split\n",
    "\n",
    "class Timer(object):\n",
    "    \"\"\"Timer class.\n",
    "\n",
    "    `Original code <https://github.com/miguelgfierro/pybase/blob/2298172a13fb4a243754acbc6029a4a2dcf72c20/log_base/timer.py>`_.\n",
    "    \n",
    "    Examples:\n",
    "        >>> import time\n",
    "        >>> t = Timer()\n",
    "        >>> t.start()\n",
    "        >>> time.sleep(1)\n",
    "        >>> t.stop()\n",
    "        >>> t.interval < 1\n",
    "        True\n",
    "        >>> with Timer() as t:\n",
    "        ...   time.sleep(1)\n",
    "        >>> t.interval < 1\n",
    "        True\n",
    "        >>> \"Time elapsed {}\".format(t) #doctest: +ELLIPSIS\n",
    "        'Time elapsed 1...'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._timer = default_timer\n",
    "        self._interval = 0\n",
    "        self.running = False\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.stop()\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{:0.4f}\".format(self.interval)\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.init = self._timer()\n",
    "        self.running = True\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer. Calculate the interval in seconds.\"\"\"\n",
    "        self.end = self._timer()\n",
    "        try:\n",
    "            self._interval = self.end - self.init\n",
    "            self.running = False\n",
    "        except AttributeError:\n",
    "            raise ValueError(\n",
    "                \"Timer has not been initialized: use start() or the contextual form with Timer() as t:\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def interval(self):\n",
    "        \"\"\"Get time interval in seconds.\n",
    "\n",
    "        Returns:\n",
    "            float: Seconds.\n",
    "        \"\"\"\n",
    "        if self.running:\n",
    "            raise ValueError(\"Timer has not been stopped, please use stop().\")\n",
    "        else:\n",
    "            return self._interval\n",
    "        \n",
    "def process_split_ratio(ratio):\n",
    "    \"\"\"Generate split ratio lists.\n",
    "\n",
    "    Args:\n",
    "        ratio (float or list): a float number that indicates split ratio or a list of float\n",
    "        numbers that indicate split ratios (if it is a multi-split).\n",
    "\n",
    "    Returns:\n",
    "        tuple: a tuple containing\n",
    "            bool: A boolean variable multi that indicates if the splitting is multi or single.\n",
    "            list: A list of normalized split ratios.\n",
    "    \"\"\"\n",
    "    if isinstance(ratio, float):\n",
    "        if ratio <= 0 or ratio >= 1:\n",
    "            raise ValueError(\"Split ratio has to be between 0 and 1\")\n",
    "\n",
    "        multi = False\n",
    "    elif isinstance(ratio, list):\n",
    "        if any([x <= 0 for x in ratio]):\n",
    "            raise ValueError(\n",
    "                \"All split ratios in the ratio list should be larger than 0.\"\n",
    "            )\n",
    "\n",
    "        # normalize split ratios if they are not summed to 1\n",
    "        if math.fsum(ratio) != 1.0:\n",
    "            ratio = [x / math.fsum(ratio) for x in ratio]\n",
    "\n",
    "        multi = True\n",
    "    else:\n",
    "        raise TypeError(\"Split ratio should be either float or a list of floats.\")\n",
    "\n",
    "    return multi, ratio\n",
    "\n",
    "def python_random_split(data, ratio=0.75, seed=42):\n",
    "    multi_split, ratio = process_split_ratio(ratio)\n",
    "\n",
    "    if multi_split:\n",
    "        splits = split_pandas_data_with_ratios(data, ratio, shuffle=True, seed=seed)\n",
    "        splits_new = [x.drop(\"split_index\", axis=1) for x in splits]\n",
    "\n",
    "        return splits_new\n",
    "    else:\n",
    "        return sk_split(data, test_size=None, train_size=ratio, random_state=seed)\n",
    "    \n",
    "def compute_ranking_predictions(\n",
    "    algo,\n",
    "    data,\n",
    "    usercol=DEFAULT_USER_COL,\n",
    "    itemcol=DEFAULT_ITEM_COL,\n",
    "    predcol=DEFAULT_PREDICTION_COL,\n",
    "    remove_seen=False,\n",
    "):\n",
    "    \"\"\"Computes predictions of an algorithm from Surprise on all users and items in data. It can be used for computing\n",
    "    ranking metrics like NDCG.\n",
    "    \n",
    "    Args:\n",
    "        algo (surprise.prediction_algorithms.algo_base.AlgoBase): an algorithm from Surprise\n",
    "        data (pd.DataFrame): the data from which to get the users and items\n",
    "        usercol (str): name of the user column\n",
    "        itemcol (str): name of the item column\n",
    "        remove_seen (bool): flag to remove (user, item) pairs seen in the training data\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with usercol, itemcol, predcol\n",
    "    \"\"\"\n",
    "    preds_lst = []\n",
    "    users = data[usercol].unique()\n",
    "    items = data[itemcol].unique()\n",
    "\n",
    "    for user in users:\n",
    "        for item in items:\n",
    "            preds_lst.append([user, item, algo.predict(user, item).est])\n",
    "    #all_predictions 所有用户对每个电影的 用户iD 电影iD 预测评分\n",
    "    all_predictions = pd.DataFrame(data=preds_lst, columns=[usercol, itemcol, predcol])\n",
    "\n",
    "    \n",
    "    if remove_seen:\n",
    "        #tempdf 存储的是用户看过的电影\n",
    "        tempdf = pd.concat(\n",
    "            [\n",
    "                data[[usercol, itemcol]],\n",
    "                pd.DataFrame(\n",
    "                    data=np.ones(data.shape[0]), columns=[\"dummycol\"], index=data.index\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        # 看过的电影和所有电影merge\n",
    "        merged = pd.merge(tempdf, all_predictions, on=[usercol, itemcol], how=\"outer\")\n",
    "        #在结果集中去掉用户看过的电影\n",
    "        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step two SVD建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise import accuracy\n",
    "import os\n",
    "\n",
    "def Svd_train():\n",
    "    # Step 1: create a Reader.\n",
    "    # A reader tells our SVD what the lower and upper bound of our ratings is.\n",
    "    # MovieLens ratings are from 1 to 5\n",
    "    reader = Reader(rating_scale=(2, 10))\n",
    "    # Step 2: create a new Dataset instance with a DataFrame and the reader\n",
    "    # The DataFrame needs to have 3 columns in this specific order: [user_id, product_id, rating]\n",
    "    train, test = python_random_split(u_data, 0.75)\n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "    train_set = Dataset.load_from_df(train, reader=Reader(rating_scale=(2, 10))).build_full_trainset()\n",
    "    svd = SVD(random_state=0, n_factors=200, n_epochs=20, verbose=True)\n",
    "\n",
    "    with Timer() as train_time:\n",
    "        svd.fit(train_set)\n",
    "\n",
    "    print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141632, 3)\n",
      "(47211, 3)\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Took 19.9701002999999 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "Svd_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_USER_COL = '用户ID'\n",
    "DEFAULT_ITEM_COL =  '电影名'\n",
    "DEFAULT_PREDICTION_COL = '评分'\n",
    "\n",
    "def Svd_predict(\n",
    "    algo,\n",
    "    data,\n",
    "    usercol=DEFAULT_USER_COL,\n",
    "    itemcol=DEFAULT_ITEM_COL,\n",
    "    predcol=DEFAULT_PREDICTION_COL,\n",
    "):\n",
    "    \"\"\"Computes predictions of an algorithm from Surprise on the data. Can be used for computing rating metrics like RMSE.\n",
    "    \n",
    "    Args:\n",
    "        algo (surprise.prediction_algorithms.algo_base.AlgoBase): an algorithm from Surprise\n",
    "        data (pd.DataFrame): the data on which to predict\n",
    "        usercol (str): name of the user column\n",
    "        itemcol (str): name of the item column\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with usercol, itemcol, predcol\n",
    "    \"\"\"\n",
    "    predictions = [\n",
    "        algo.predict(getattr(row, usercol), getattr(row, itemcol))\n",
    "        for row in data.itertuples()\n",
    "    ]\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    predictions = predictions.rename(\n",
    "        index=str, columns={\"uid\": usercol, \"iid\": itemcol, \"est\": predcol}\n",
    "    )\n",
    "    return predictions.drop([\"details\", \"r_ui\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions():\n",
    "    predictions = Svd_predict(svd, test, usercol='用户ID', itemcol='电影名')\n",
    "    print(predictions.head())\n",
    "    print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    用户ID    电影名        评分\n",
      "0   3352    猪之日  6.751689\n",
      "1   7303  拉撒路报告  6.630192\n",
      "2   8946   一丝偶然  6.924515\n",
      "3  11592  再见艳阳天  7.116095\n",
      "4   9885  夏天的故事  7.474689\n",
      "(47211, 3)\n"
     ]
    }
   ],
   "source": [
    "get_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step three 从总数据集中采样一部分样本参加训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampledata_train():\n",
    "    train_all,test  = python_random_split(u_data, 0.999)\n",
    "    \n",
    "    train_all = train_all.sample(frac=0.02, replace=True, random_state=1)\n",
    "    print(train_all.shape)\n",
    "    train_all_set = Dataset.load_from_df(train_all, reader=Reader(rating_scale=(2, 10))).build_full_trainset()\n",
    "\n",
    "    svd = SVD(random_state=0, n_factors=200, n_epochs=30, verbose=True)\n",
    "\n",
    "    with Timer() as train_time:\n",
    "        svd.fit(train_all_set)\n",
    "\n",
    "    print(\"Took {} seconds for training.\".format(train_time.interval))\n",
    "    return svd,train_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step four 根据用户观看过的电影的平均数13个。给每个用户推荐其最有可能观看的10个电影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_predictions():\n",
    "    svd,train_all = sampledata_train()\n",
    "    with Timer() as test_time:\n",
    "        all_predictions = compute_ranking_predictions(svd, train_all, usercol='用户ID', itemcol='电影名', remove_seen=True)\n",
    "    \n",
    "    print(\"Took {} seconds for prediction.\".format(test_time.interval))\n",
    "    \n",
    "    #按评分简单排序\n",
    "    all_predictions  = all_predictions.sort_values(by=['用户ID','评分'],ascending=False)\n",
    "    #召回\n",
    "    #对每个用户取排序后前20的电影名\n",
    "    user_count = 0\n",
    "    for user in all_predictions.用户ID.unique():\n",
    "        usertemp_df = all_predictions[all_predictions['用户ID'] == user][:11]\n",
    "        if user_count == 0:\n",
    "            dfret = usertemp_df.copy(deep=True)\n",
    "            user_count += 1\n",
    "        else:\n",
    "            dfret = pd.concat([dfret,usertemp_df],axis=0,ignore_index=True)\n",
    "    print('dfret shape',dfret.shape)\n",
    "    \n",
    "    #召回结果保存\n",
    "    dfret.to_csv(\"./dfrecall.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3773, 3)\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Took 0.5960879000012937 seconds for training.\n",
      "Took 76.36160069999823 seconds for prediction.\n",
      "dfret shape (32241, 3)\n"
     ]
    }
   ],
   "source": [
    "get_all_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step five召回集数据特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_data_process(dfuserin,dfmoviein):\n",
    "    ur1 = dfuserin.groupby(['用户ID']).评分.agg( {'user_rating_avg':np.mean ,\n",
    "                                           'user_rating_max':np.max ,\n",
    "                                           'user_rating_min':np.min ,\n",
    "                                           'user_rating_median':np.median\n",
    "                                          }).reset_index()\n",
    "\n",
    "    dfuserin['用户评论次数_观看电影个数'] = dfuserin.groupby(['用户ID'])['评分'].transform('count')\n",
    "\n",
    "    u_data = pd.merge(ur1,dfuserin,on='用户ID',how = 'inner')\n",
    "\n",
    "    user_and_movies_df = pd.merge(u_data,movies_df,on='电影名',how='inner')\n",
    "   \n",
    "    return user_and_movies_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = load_movies_dataset()\n",
    "dfdata = pd.read_csv('./dfrecall.csv')\n",
    "dfa = call_data_process(dfdata,movies_df).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138660, 14)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['用户ID', 'user_rating_avg', 'user_rating_max', 'user_rating_min',\n",
       "       'user_rating_median', '电影名', '评分', '用户评论次数_观看电影个数', '类型', '主演', '地区',\n",
       "       '导演', '特色', '豆瓣网评分'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.to_csv('./dfrecallfeature.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
